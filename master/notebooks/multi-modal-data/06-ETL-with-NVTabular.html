<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ETL with NVTabular &mdash; Merlin HugeCTR  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Training HugeCTR Model with Pretrained Embeddings" href="07-Training-with-HugeCTR.html" />
    <link rel="prev" title="Creating Multi-Modal Movie Feature Store" href="05-Create-Feature-Store.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Merlin HugeCTR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">HugeCTR Library</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_user_guide.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_feature_details_intro.html">Features in Detail</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../hugectr_example_notebooks.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../hugectr_wdl_prediction.html">HugeCTR Wide and Deep Model with Criteo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hugectr2onnx_demo.html">HugeCTR to ONNX Converter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../continuous_training.html">HugeCTR Continuous Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ecommerce-example.html">Merlin ETL, training and inference demo on the e-Commerce behavior data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../movie-lens-example.html">HugeCTR demo on Movie lens data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hugectr_criteo.html">HugeCTR Python Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multi_gpu_offline_inference.html">Multi-GPU Offline Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="00-Intro.html">Training Recommender Systems on Multi-modal Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="01-Download-Convert.html">MovieLens-25M: Download and Convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-Feature-Extraction-Poster.html">Movie Poster Feature Extraction with ResNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-Feature-Extraction-Text.html">Movie Synopsis Feature Extraction with Bart text summarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-Feature-Extraction-Text.html#Download-pretrained-BART-model">Download pretrained BART model</a></li>
<li class="toctree-l2"><a class="reference internal" href="05-Create-Feature-Store.html">Creating Multi-Modal Movie Feature Store</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ETL with NVTabular</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Defining-our-Preprocessing-Pipeline">Defining our Preprocessing Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Running-the-pipeline">Running the pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Checking-the-pre-processing-outputs">Checking the pre-processing outputs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="07-Training-with-HugeCTR.html">Training HugeCTR Model with Pretrained Embeddings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api/index.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hugectr_contributor_guide.html">Contributing to HugeCTR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../additional_resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Merlin HugeCTR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../hugectr_example_notebooks.html">HugeCTR Example Notebooks</a></li>
      <li class="breadcrumb-item active">ETL with NVTabular</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Copyright 2021 NVIDIA Corporation. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
</pre></div>
</div>
</div>
<p><img alt="f0fe04efb4044b31afb00890c2c12bcf" src="http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png" /></p>
<div class="section" id="ETL-with-NVTabular">
<h1>ETL with NVTabular<a class="headerlink" href="#ETL-with-NVTabular" title="Permalink to this headline"></a></h1>
<p>NVTabular is a feature engineering and preprocessing library for tabular data designed to quickly and easily manipulate terabyte scale datasets used to train deep learning based recommender systems. It provides a high level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS cuDF library.</p>
<p>Deep Learning models require the input feature in a specific format. Categorical features needs to be continuous integers (0, …, |C|) to use them with an embedding layer. We will use NVTabular to preprocess the categorical features.</p>
<p>This notebook will prepare the Movielens data for use with HugeCTR training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># External dependencies
!apt update &amp;&amp; apt install -y graphviz

import cudf
import os
import shutil
import numpy as np

import nvtabular as nvt

from os import path
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Hit:1 http://security.ubuntu.com/ubuntu focal-security InRelease
Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease
Hit:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease
Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease
Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease
Reading package lists... Done<span class="ansi-yellow-fg">
Building dependency tree
Reading state information... Done
16 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them.
Reading package lists... Done
Building dependency tree
Reading state information... Done
graphviz is already the newest version (2.42.2-3build2).
The following packages were automatically installed and are no longer required:
  cmake-data libarchive13 librhash0 libuv1
Use &#39;apt autoremove&#39; to remove them.
0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.</span>
</pre></div></div>
</div>
<p>We define our base input directory, containing the data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>INPUT_DATA_DIR = &#39;./data&#39;
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>movies = cudf.read_parquet(os.path.join(INPUT_DATA_DIR, &quot;movies_converted.parquet&quot;))
movies.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="section" id="Defining-our-Preprocessing-Pipeline">
<h2>Defining our Preprocessing Pipeline<a class="headerlink" href="#Defining-our-Preprocessing-Pipeline" title="Permalink to this headline"></a></h2>
<p>The first step is to define the feature engineering and preprocessing pipeline. NVTabular has already implemented multiple calculations, called <code class="docutils literal notranslate"><span class="pre">ops</span></code>. An <code class="docutils literal notranslate"><span class="pre">op</span></code> can be applied to a <code class="docutils literal notranslate"><span class="pre">ColumnGroup</span></code> from an overloaded <code class="docutils literal notranslate"><span class="pre">&gt;&gt;</span></code> operator, which in turn returns a new <code class="docutils literal notranslate"><span class="pre">ColumnGroup</span></code>. A <code class="docutils literal notranslate"><span class="pre">ColumnGroup</span></code> is a list of column names as text. <strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span> <span class="n">column_name</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">op1</span> <span class="o">&gt;&gt;</span> <span class="n">op2</span> <span class="o">&gt;&gt;</span> <span class="o">...</span>
</pre></div>
</div>
<p>This may sounds more complicated as it is. Let’s define our first pipeline for the MovieLens dataset.</p>
<p>Currently, our dataset consists of two separate dataframes. First, we use the <code class="docutils literal notranslate"><span class="pre">JoinExternal</span></code> operator to <code class="docutils literal notranslate"><span class="pre">left-join</span></code> the metadata (genres) to our rating dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>CATEGORICAL_COLUMNS = [&quot;userId&quot;, &quot;movieId&quot;]
LABEL_COLUMNS = [&quot;rating&quot;]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>joined = [&quot;userId&quot;, &quot;movieId&quot;] &gt;&gt; nvt.ops.JoinExternal(movies, on=[&quot;movieId&quot;])
</pre></div>
</div>
</div>
<p>Data pipelines are <strong>Directed Acyclic Graphs (DAGs)</strong>. We can visualize them with <code class="docutils literal notranslate"><span class="pre">graphviz</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>joined.graph
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_multi-modal-data_06-ETL-with-NVTabular_11_0.svg" src="../../_images/notebooks_multi-modal-data_06-ETL-with-NVTabular_11_0.svg" /></div>
</div>
<p>Embedding Layers of neural networks require that categorical features are contiguous, incremental Integers: 0, 1, 2, … , |C|-1. We need to ensure that our categorical features fullfil the requirement.</p>
<p>Currently, our genres are a list of Strings. In addition, we should transform the single-hot categorical features userId and movieId, as well. NVTabular provides the operator <code class="docutils literal notranslate"><span class="pre">Categorify</span></code>, which provides this functionality with a high-level API out of the box. In NVTabular release v0.3, list support was added for multi-hot categorical features. Both works in the same way with no need for changes.</p>
<p>Next, we will add <code class="docutils literal notranslate"><span class="pre">Categorify</span></code> for our categorical features (single hot: userId, movieId and multi-hot: genres).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cat_features = joined &gt;&gt; nvt.ops.Categorify()
movieId_dup = cat_features[&quot;movieId&quot;] &gt;&gt; nvt.ops.Rename(postfix=&#39;_duplicate&#39;)
</pre></div>
</div>
</div>
<p>The ratings are on a scale between 1-5. We want to predict a binary target with 1 for ratings <code class="docutils literal notranslate"><span class="pre">&gt;3</span></code> and 0 for ratings <code class="docutils literal notranslate"><span class="pre">&lt;=3</span></code>. We use the <a class="reference external" href="https://nvidia.github.io/NVTabular/main/api/ops/lambdaop.html">LambdaOp</a> for it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ratings = nvt.ColumnGroup([&quot;rating&quot;]) &gt;&gt; (lambda col: (col &gt; 3).astype(&quot;int8&quot;))
</pre></div>
</div>
</div>
<p>We will also be adding a duplicate of the <code class="docutils literal notranslate"><span class="pre">movieId</span></code> field, which will be used for looking up pretrained movie embedding features.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>output = cat_features + ratings + movieId_dup
(output).graph
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_multi-modal-data_06-ETL-with-NVTabular_17_0.svg" src="../../_images/notebooks_multi-modal-data_06-ETL-with-NVTabular_17_0.svg" /></div>
</div>
<p>We initialize our NVTabular <code class="docutils literal notranslate"><span class="pre">workflow</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>workflow = nvt.Workflow(output)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Running-the-pipeline">
<h2>Running the pipeline<a class="headerlink" href="#Running-the-pipeline" title="Permalink to this headline"></a></h2>
<p>In general, the <code class="docutils literal notranslate"><span class="pre">Op</span></code>s in our <code class="docutils literal notranslate"><span class="pre">Workflow</span></code> will require measurements of statistical properties of our data in order to be leveraged. For example, the <code class="docutils literal notranslate"><span class="pre">Normalize</span></code> op requires measurements of the dataset mean and standard deviation, and the <code class="docutils literal notranslate"><span class="pre">Categorify</span></code> op requires an accounting of all the categories a particular feature can manifest. However, we frequently need to measure these properties across datasets which are too large to fit into GPU memory (or CPU memory for that matter) at once.</p>
<p>NVTabular solves this by providing the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class, which breaks a set of parquet or csv files into into a collection of <code class="docutils literal notranslate"><span class="pre">cudf.DataFrame</span></code> chunks that can fit in device memory. The main purpose of this class is to abstract away the raw format of the data, and to allow other NVTabular classes to reliably materialize a dask_cudf.DataFrame collection (and/or collection-based iterator) on demand. Under the hood, the data decomposition corresponds to the construction of a
<a class="reference external" href="https://docs.rapids.ai/api/cudf/stable/dask-cudf.html">dask_cudf.DataFrame</a> object. By representing our dataset as a lazily-evaluated <a class="reference external" href="https://dask.org/">Dask</a> collection, we can handle the calculation of complex global statistics (and later, can also iterate over the partitions while feeding data into a neural network). <code class="docutils literal notranslate"><span class="pre">part_size</span></code> defines the size read into GPU-memory at once.</p>
<p>Now instantiate dataset iterators to loop through our dataset (which we couldn’t fit into GPU memory). HugeCTR expect the categorical input columns as <code class="docutils literal notranslate"><span class="pre">int64</span></code> and continuous/label columns as <code class="docutils literal notranslate"><span class="pre">float32</span></code> We need to enforce the required HugeCTR data types, so we set them in a dictionary and give as an argument when creating our dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dict_dtypes = {}

for col in CATEGORICAL_COLUMNS:
    dict_dtypes[col] = np.int64

for col in LABEL_COLUMNS:
    dict_dtypes[col] = np.float32
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_dataset = nvt.Dataset([os.path.join(INPUT_DATA_DIR, &quot;train.parquet&quot;)], part_size=&quot;100MB&quot;)
valid_dataset = nvt.Dataset([os.path.join(INPUT_DATA_DIR, &quot;valid.parquet&quot;)], part_size=&quot;100MB&quot;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/nvtabular/nvtabular/io/parquet.py:285: UserWarning: Row group memory size (640002432) (bytes) of parquet file is bigger than requested part_size (100000000) for the NVTabular dataset.A row group memory size of 128 MB is generally recommended. You can find info on how to set the row group size of parquet files in https://nvidia-merlin.github.io/NVTabular/main/resources/troubleshooting.html#setting-the-row-group-size-for-the-parquet-files
  warnings.warn(
/nvtabular/nvtabular/io/parquet.py:285: UserWarning: Row group memory size (160000608) (bytes) of parquet file is bigger than requested part_size (100000000) for the NVTabular dataset.A row group memory size of 128 MB is generally recommended. You can find info on how to set the row group size of parquet files in https://nvidia-merlin.github.io/NVTabular/main/resources/troubleshooting.html#setting-the-row-group-size-for-the-parquet-files
  warnings.warn(
</pre></div></div>
</div>
<p>Now that we have our datasets, we’ll apply our <code class="docutils literal notranslate"><span class="pre">Workflow</span></code> to them and save the results out to parquet files for fast reading at train time. Similar to the <code class="docutils literal notranslate"><span class="pre">scikit</span> <span class="pre">learn</span></code> API, we collect the statistics of our train dataset with <code class="docutils literal notranslate"><span class="pre">.fit</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%time

workflow.fit(train_dataset)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 554 ms, sys: 427 ms, total: 981 ms
Wall time: 1.04 s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;nvtabular.workflow.workflow.Workflow at 0x7fbb086a3370&gt;
</pre></div></div>
</div>
<p>We clear our output directories.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Make sure we have a clean output path
if path.exists(os.path.join(INPUT_DATA_DIR, &quot;train-hugectr&quot;)):
    shutil.rmtree(os.path.join(INPUT_DATA_DIR, &quot;train-hugectr&quot;))
if path.exists(os.path.join(INPUT_DATA_DIR, &quot;valid-hugectr&quot;)):
    shutil.rmtree(os.path.join(INPUT_DATA_DIR, &quot;valid-hugectr&quot;))
</pre></div>
</div>
</div>
<p>We transform our workflow with <code class="docutils literal notranslate"><span class="pre">.transform</span></code>. We are going to add only <code class="docutils literal notranslate"><span class="pre">'userId',</span> <span class="pre">'movieId'</span></code> columns to <code class="docutils literal notranslate"><span class="pre">_metadata.json</span></code>, because this json file will be needed for HugeCTR training to obtain the required information from all the rows in each parquet file.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%time
workflow.transform(train_dataset).to_parquet(
    output_path=os.path.join(INPUT_DATA_DIR, &quot;train-hugectr&quot;),
    shuffle=nvt.io.Shuffle.PER_PARTITION,
    cats=[&quot;userId&quot;, &quot;movieId&quot;],
    labels=[&quot;rating&quot;],
    dtypes=dict_dtypes,
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs
Wall time: 5.25 µs
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%time
workflow.transform(valid_dataset).to_parquet(
    output_path=os.path.join(INPUT_DATA_DIR, &quot;valid-hugectr&quot;),
    shuffle=False,
    cats=[&quot;userId&quot;, &quot;movieId&quot;],
    labels=[&quot;rating&quot;],
    dtypes=dict_dtypes,
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 2 µs, sys: 2 µs, total: 4 µs
Wall time: 6.68 µs
</pre></div></div>
</div>
<p>We can take a look in the output dir.</p>
<p>In the next notebooks, we will train a deep learning model. Our training pipeline requires information about the data schema to define the neural network architecture. We will save the NVTabular workflow to disk tha we can restore it in the next notebooks.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>workflow.save(os.path.join(INPUT_DATA_DIR, &quot;workflow-hugectr&quot;))
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from nvtabular.ops import get_embedding_sizes

embeddings = get_embedding_sizes(workflow)
print(embeddings)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;userId&#39;: (162542, 512), &#39;movieId&#39;: (56586, 512), &#39;movieId_duplicate&#39;: (56586, 512)}
</pre></div></div>
</div>
</div>
<div class="section" id="Checking-the-pre-processing-outputs">
<h2>Checking the pre-processing outputs<a class="headerlink" href="#Checking-the-pre-processing-outputs" title="Permalink to this headline"></a></h2>
<p>We can take a look on the data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import glob

TRAIN_PATHS = sorted(glob.glob(os.path.join(INPUT_DATA_DIR, &quot;train-hugectr&quot;, &quot;*.parquet&quot;)))
VALID_PATHS = sorted(glob.glob(os.path.join(INPUT_DATA_DIR, &quot;valid-hugectr&quot;, &quot;*.parquet&quot;)))
TRAIN_PATHS, VALID_PATHS
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
([&#39;./data/train-hugectr/part_0.parquet&#39;],
 [&#39;./data/valid-hugectr/part_0.parquet&#39;])
</pre></div></div>
</div>
<p>We can see, that genres are a list of Integers</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>df = cudf.read_parquet(TRAIN_PATHS[0])
df.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>movieId_duplicate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>26460</td>
      <td>874</td>
      <td>0.0</td>
      <td>874</td>
    </tr>
    <tr>
      <th>1</th>
      <td>97438</td>
      <td>1704</td>
      <td>0.0</td>
      <td>1704</td>
    </tr>
    <tr>
      <th>2</th>
      <td>105574</td>
      <td>3568</td>
      <td>0.0</td>
      <td>3568</td>
    </tr>
    <tr>
      <th>3</th>
      <td>39464</td>
      <td>30</td>
      <td>1.0</td>
      <td>30</td>
    </tr>
    <tr>
      <th>4</th>
      <td>127724</td>
      <td>98</td>
      <td>1.0</td>
      <td>98</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="05-Create-Feature-Store.html" class="btn btn-neutral float-left" title="Creating Multi-Modal Movie Feature Store" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="07-Training-with-HugeCTR.html" class="btn btn-neutral float-right" title="Training HugeCTR Model with Pretrained Embeddings" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: master
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Branches</dt>
      <dd><a href="06-ETL-with-NVTabular.html">master</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>